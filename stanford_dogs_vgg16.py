# -*- coding: utf-8 -*-
"""Stanford_dogs-VGG16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZaKdV84S0zPnLycK-HSQqCvvFFkiZZzJ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras

from tensorflow.python.keras.layers import Conv2D, MaxPool2D, Dense, Input, Flatten, Activation, Dropout, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPooling2D
from tensorflow.python.keras.models import sequential, Model
from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from tensorflow.python.keras.optimizers import Adam, SGD, RMSprop
from keras.utils import np_utils
from skimage.transform import resize, rescale
from keras.applications.vgg16 import  VGG16, preprocess_input
from keras.applications.resnet50 import resnet50
import os
import cv2

import tarfile
dogs_images = tarfile.open('/content/drive/My Drive/Spring_2020/NN/Deep Learning/NN_Datasets/Stanford dogs/images.tar')
dogs_images.extractall(path='/content/drive/My Drive/Spring_2020/NN/Deep Learning/NN_Datasets/Stanford dogs/Images')

pip install split-folders tqdm

import split_folders

split_folders.ratio('/content/drive/My Drive/Spring_2020/NN/Deep Learning/NN_Datasets/Stanford dogs/Images/Images', 
                    output='/content/drive/My Drive/Spring_2020/NN/Deep Learning/NN_Datasets/Stanford dogs/Images/Output', seed=134, ratio=(0.8, 0.2))

test_imgs_count = sum([len(files) for r, d, files in os.walk("/content/drive/My Drive/Spring_2020/NN/Deep Learning/NN_Datasets/Stanford dogs/Images/Output/train")])
print(test_imgs_count)

train_imgs_count = sum([len(files) for r, d, files in os.walk("/content/drive/My Drive/Spring_2020/NN/Deep Learning/NN_Datasets/Stanford dogs/Images/Output/val")])
print(train_imgs_count)

image = cv2.imread('/content/drive/My Drive/Spring_2020/NN/Deep Learning/NN_Datasets/Stanford dogs/Images/Output/train/n02085620-Chihuahua/n02085620_10074.jpg')

image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)
plt.figure()
plt.imshow(image)

img_width = 224
img_height = 224
batch_size = 40
nb_train_samples = 16418
nb_validation_samples = 4162
epochs = 50
input_shape = Input(shape = (224,224,3))

# this is the augmentation configuration we will use for training
train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)
# this is the augmentation configuration we will use for testing:
# only rescaling
test_datagen = ImageDataGenerator(rescale=1. / 255)

train_generator = train_datagen.flow_from_directory(
    '/content/drive/My Drive/Spring_2020/NN/Deep Learning/NN_Datasets/Stanford dogs/Images/Output/train',
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical')
validation_generator = test_datagen.flow_from_directory(
    '/content/drive/My Drive/Spring_2020/NN/Deep Learning/NN_Datasets/Stanford dogs/Images/Output/val',
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical')

base_model = keras.applications.VGG16(input_shape=(224, 224, 3), include_top=False, weights='imagenet')

output = base_model.layers[-1].output
output = keras.layers.Flatten()(output)
output = Dense(120, activation='softmax')(output)
model = Model(base_model.input, output)

model.compile(loss='categorical_crossentropy',
              optimizer='Adam',
              metrics=['accuracy'])

model.summary()

history = model.fit_generator(
    train_generator,
    steps_per_epoch=nb_train_samples // batch_size,
    epochs=5,
    validation_data=validation_generator,
    validation_steps=nb_validation_samples // batch_size)